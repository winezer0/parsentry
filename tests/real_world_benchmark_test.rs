use anyhow::Result;
use parsentry::analyzer::analyze_file;
use parsentry::locales::Language as LocaleLanguage;
use parsentry::parser::CodeParser;
use parsentry::response::VulnType;
use parsentry::security_patterns::Language;
use std::collections::HashMap;
use tempfile::tempdir;

/// å®Ÿä¸–ç•Œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ
/// æ—¢çŸ¥ã®CVEäº‹ä¾‹ã€å®Ÿéš›ã®è„†å¼±æ€§ã‚µãƒ³ãƒ—ãƒ«ã€æ¥­ç•Œæ¨™æº–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å¯¾ã™ã‚‹æ¤œå‡ºç²¾åº¦ã‚’æ¸¬å®š
/// ã“ã‚Œã¯Parsentryã®å®Ÿç”¨æ€§ã‚’è©•ä¾¡ã™ã‚‹æœ€ã‚‚é‡è¦ãªãƒ†ã‚¹ãƒˆ

#[derive(Debug, Clone)]
struct RealWorldBenchmark {
    name: &'static str,
    cve_id: Option<&'static str>,
    language: Language,
    code: &'static str,
    expected_vulnerabilities: Vec<VulnType>,
    expected_confidence_min: i32,
    severity: BenchmarkSeverity,
    _description: &'static str,
    _real_world_context: &'static str,
}

#[derive(Debug, Clone)]
enum BenchmarkSeverity {
    Critical,  // CVSS 9.0-10.0
    High,      // CVSS 7.0-8.9  
    Medium,    // CVSS 4.0-6.9
}

fn get_real_world_benchmarks() -> Vec<RealWorldBenchmark> {
    vec![
    // === Critical Severity Benchmarks ===
    RealWorldBenchmark {
        name: "CVE-2021-44228 Log4jç±»ä¼¼ - Command Injection",
        cve_id: Some("CVE-2021-44228"),
        language: Language::Python,
        code: r#"
import logging
import subprocess

def log_user_activity(user_input, action):
    # è„†å¼±ï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãŒç›´æ¥ãƒ­ã‚°ã«è¨˜éŒ²ã•ã‚Œã€JNDIãƒ«ãƒƒã‚¯ã‚¢ãƒƒãƒ—é¡ä¼¼ã®å‡¦ç†
    log_message = f"User activity: {user_input} performed {action}"
    
    # ã•ã‚‰ã«å±é™ºï¼šãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã«ä½¿ç”¨ã•ã‚Œã‚‹
    if "exec:" in user_input:
        command = user_input.replace("exec:", "")
        result = subprocess.run(command, shell=True, capture_output=True, text=True)
        logging.info(f"Command executed: {result.stdout}")
    
    logging.info(log_message)
    return log_message

# æ‚ªç”¨ä¾‹:
# log_user_activity("exec:rm -rf /tmp/*", "file_cleanup")
"#,
        expected_vulnerabilities: vec![VulnType::RCE],
        expected_confidence_min: 8,
        severity: BenchmarkSeverity::Critical,
        _description: "Log4jæ§˜ã®JNDIã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³é¡ä¼¼ãƒ‘ã‚¿ãƒ¼ãƒ³ - ã‚³ãƒãƒ³ãƒ‰ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³",
        _real_world_context: "Log4jã®JNDI lookupè„†å¼±æ€§ã‚’æ¨¡å€£ã€‚å®Ÿéš›ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãŒãƒ­ã‚°ã«è¨˜éŒ²ã•ã‚Œã€ç‰¹æ®Šãªæ–‡å­—åˆ—ãŒã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã«ã¤ãªãŒã‚‹",
    },

    RealWorldBenchmark {
        name: "SQL Injection - Union-based attack vector",
        cve_id: None,
        language: Language::Python,
        code: r#"
import sqlite3

def get_user_profile(user_id, db_connection):
    # å…¸å‹çš„ãªSQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³è„†å¼±æ€§
    query = f"SELECT username, email, role FROM users WHERE id = {user_id}"
    cursor = db_connection.execute(query)
    result = cursor.fetchone()
    
    if result:
        return {
            'username': result[0],
            'email': result[1], 
            'role': result[2]
        }
    return None

def get_user_by_email(email, db_connection):
    # ã•ã‚‰ã«å±é™ºï¼šæ–‡å­—åˆ—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç›´æ¥åŸ‹ã‚è¾¼ã¿
    query = f"SELECT * FROM users WHERE email = '{email}'"
    cursor = db_connection.execute(query)
    return cursor.fetchall()

# æ‚ªç”¨ä¾‹:
# get_user_profile("1 UNION SELECT password,secret,admin FROM admin_users--", conn)
# get_user_by_email("admin@test.com' OR '1'='1' --", conn)
"#,
        expected_vulnerabilities: vec![VulnType::SQLI],
        expected_confidence_min: 9,
        severity: BenchmarkSeverity::Critical,
        _description: "å…¸å‹çš„ãªSQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ - UNIONãƒ™ãƒ¼ã‚¹æ”»æ’ƒ",
        _real_world_context: "å®Ÿéš›ã®Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚ˆãè¦‹ã‚‰ã‚Œã‚‹SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã€‚æ”»æ’ƒè€…ãŒUNIONæ–‡ã§ç®¡ç†è€…æƒ…å ±ã‚’çªƒå–å¯èƒ½",
    },

    RealWorldBenchmark {
        name: "Deserialization RCE - pickle unsafe loading",
        cve_id: None,
        language: Language::Python,
        code: r#"
import pickle
import base64

def deserialize_user_session(session_data):
    # æ¥µã‚ã¦å±é™ºï¼šä¿¡é ¼ã§ããªã„ãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³
    try:
        decoded_data = base64.b64decode(session_data)
        user_session = pickle.loads(decoded_data)
        return user_session
    except Exception as e:
        return {"error": str(e)}

def restore_user_state(user_id, session_cookie):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’Cookieã‹ã‚‰å¾©å…ƒ
    if session_cookie:
        session = deserialize_user_session(session_cookie)
        if "user_id" in session and session["user_id"] == user_id:
            return session
    return None

# æ‚ªç”¨ä¾‹:
# æ”»æ’ƒè€…ã¯æ‚ªæ„ã®ã‚ã‚‹pickleãƒ‡ãƒ¼ã‚¿ã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦Cookieã«è¨­å®š
# import os; os.system('rm -rf /')  ã®ã‚ˆã†ãªã‚³ãƒ¼ãƒ‰ãŒå®Ÿè¡Œã•ã‚Œã‚‹
"#,
        expected_vulnerabilities: vec![VulnType::RCE],
        expected_confidence_min: 9,
        severity: BenchmarkSeverity::Critical,
        _description: "Pythonãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³è„†å¼±æ€§ - pickle RCE",
        _real_world_context: "å®Ÿéš›ã®Webã‚¢ãƒ—ãƒªã§ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã«pickleã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆã®å…¸å‹çš„ãªè„†å¼±æ€§ã€‚æ”»æ’ƒè€…ãŒä»»æ„ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œå¯èƒ½",
    },

    // === High Severity Benchmarks ===
    RealWorldBenchmark {
        name: "DOM-based XSS - innerHTML injection",
        cve_id: None,
        language: Language::JavaScript,
        code: r#"
function displayUserMessage(messageId) {
    // URLãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰ç›´æ¥å€¤ã‚’å–å¾—
    const urlParams = new URLSearchParams(window.location.search);
    const userMessage = urlParams.get('message');
    
    // å±é™ºï¼šã‚µãƒ‹ã‚¿ã‚¤ã‚ºãªã—ã§DOMæ“ä½œ
    if (userMessage) {
        document.getElementById('message-display').innerHTML = 
            `<div class="user-message">Message: ${userMessage}</div>`;
    }
}

function updateUserProfile(userData) {
    // ã•ã‚‰ã«å±é™ºï¼šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®ç›´æ¥å±•é–‹
    const profileDiv = document.getElementById('profile');
    profileDiv.innerHTML = `
        <h2>Welcome ${userData.name}</h2>
        <p>Bio: ${userData.bio}</p>
        <p>Website: <a href="${userData.website}">${userData.website}</a></p>
    `;
}

// æ‚ªç”¨ä¾‹:
// ?message=<script>alert('XSS')</script>
// userData.name = "<img src=x onerror=alert('XSS')>"
"#,
        expected_vulnerabilities: vec![VulnType::XSS],
        expected_confidence_min: 8,
        severity: BenchmarkSeverity::High,
        _description: "DOM-based XSS - innerHTML ã«ã‚ˆã‚‹ç›´æ¥æ³¨å…¥",
        _real_world_context: "SPAã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚ˆãè¦‹ã‚‰ã‚Œã‚‹DOM-based XSSã€‚URLãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒç›´æ¥DOMæ“ä½œã«ä½¿ç”¨",
    },

    RealWorldBenchmark {
        name: "Path Traversal - File include vulnerability",
        cve_id: None,
        language: Language::Python,
        code: r#"
import os

def serve_static_file(filename):
    # å±é™ºï¼šãƒ‘ã‚¹æ¤œè¨¼ãªã—ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹
    static_dir = "/var/www/static/"
    file_path = static_dir + filename
    
    try:
        with open(file_path, 'r') as f:
            content = f.read()
        return content
    except FileNotFoundError:
        return "File not found"

def load_template(template_name):
    # ã•ã‚‰ã«å±é™ºï¼šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å‹•çš„èª­ã¿è¾¼ã¿
    template_dir = "/app/templates/"
    full_path = os.path.join(template_dir, template_name)
    
    # os.path.joinã§ã‚‚å±é™ºï¼šçµ¶å¯¾ãƒ‘ã‚¹æŒ‡å®šã§å›é¿ã•ã‚Œã‚‹
    with open(full_path, 'r') as f:
        return f.read()

def include_user_file(user_id, file_type):
    # æœ€ã‚‚å±é™ºï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¶å¾¡å¯èƒ½ãªè¤‡æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    base_path = f"/app/user_data/{user_id}/"
    file_path = base_path + file_type + ".txt"
    
    return open(file_path).read()

# æ‚ªç”¨ä¾‹:
# serve_static_file("../../../etc/passwd")
# load_template("../../../../etc/shadow")
# include_user_file("../admin", "../../../etc/passwd")
"#,
        expected_vulnerabilities: vec![VulnType::LFI],
        expected_confidence_min: 8,
        severity: BenchmarkSeverity::High,
        _description: "ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«æ”»æ’ƒ - ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«",
        _real_world_context: "Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã®ãƒ•ã‚¡ã‚¤ãƒ«æä¾›æ©Ÿèƒ½ã«ãŠã‘ã‚‹å…¸å‹çš„ãªè„†å¼±æ€§ã€‚æ”»æ’ƒè€…ãŒã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½",
    },

    RealWorldBenchmark {
        name: "SSRF - Internal service access",
        cve_id: None,
        language: Language::Python,
        code: r#"
import requests

def fetch_external_image(image_url):
    # å±é™ºï¼šURLæ¤œè¨¼ãªã—ã®å¤–éƒ¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    try:
        response = requests.get(image_url, timeout=10)
        if response.status_code == 200:
            return response.content
        return None
    except Exception:
        return None

def proxy_api_request(api_endpoint, user_token):
    # ã•ã‚‰ã«å±é™ºï¼šå†…éƒ¨APIã¸ã®ãƒ—ãƒ­ã‚­ã‚·
    internal_base = "http://internal-api:8080"
    full_url = f"{internal_base}/{api_endpoint}"
    
    headers = {
        'Authorization': f'Bearer {user_token}',
        'X-Forwarded-For': '127.0.0.1'
    }
    
    response = requests.get(full_url, headers=headers)
    return response.json()

def health_check_service(service_name):
    # æœ€ã‚‚å±é™ºï¼šå®Œå…¨ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¶å¾¡å¯èƒ½ãªURL
    health_url = f"http://{service_name}/health"
    response = requests.get(health_url)
    return response.status_code == 200

# æ‚ªç”¨ä¾‹:
# fetch_external_image("http://169.254.169.254/latest/meta-data/iam/security-credentials/")
# proxy_api_request("../../admin/users", "attacker_token")  
# health_check_service("localhost:22")  # ãƒãƒ¼ãƒˆã‚¹ã‚­ãƒ£ãƒ³
"#,
        expected_vulnerabilities: vec![VulnType::SSRF],
        expected_confidence_min: 8,
        severity: BenchmarkSeverity::High,
        _description: "SSRFæ”»æ’ƒ - å†…éƒ¨ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚¯ã‚»ã‚¹",
        _real_world_context: "ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ç’°å¢ƒã§ã®å…¸å‹çš„ãªSSRFè„†å¼±æ€§ã€‚æ”»æ’ƒè€…ãŒå†…éƒ¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¹ã‚­ãƒ£ãƒ³ã‚„ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿çªƒå–å¯èƒ½",
    },

    // === Medium Severity Benchmarks ===
    RealWorldBenchmark {
        name: "IDOR - Direct object reference",
        cve_id: None,
        language: Language::JavaScript,
        code: r#"
// Express.js route handlers

app.get('/api/documents/:docId', (req, res) => {
    const docId = req.params.docId;
    
    // å±é™ºï¼šèªå¯ãƒã‚§ãƒƒã‚¯ãªã—ã®ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹
    const document = database.getDocument(docId);
    if (document) {
        res.json(document);
    } else {
        res.status(404).json({error: 'Document not found'});
    }
});

app.delete('/api/users/:userId/files/:fileId', (req, res) => {
    const userId = req.params.userId;
    const fileId = req.params.fileId;
    
    // ã•ã‚‰ã«å±é™ºï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼IDãƒã‚§ãƒƒã‚¯ãªã—ã®å‰Šé™¤
    const deleted = database.deleteFile(fileId);
    if (deleted) {
        res.json({message: 'File deleted successfully'});
    } else {
        res.status(404).json({error: 'File not found'});
    }
});

app.put('/api/profiles/:profileId', (req, res) => {
    const profileId = req.params.profileId;
    const updates = req.body;
    
    // æœ€ã‚‚å±é™ºï¼šæ‰€æœ‰è€…ãƒã‚§ãƒƒã‚¯ãªã—ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°
    const updated = database.updateProfile(profileId, updates);
    res.json({updated: true, profile: updated});
});

// æ‚ªç”¨ä¾‹:
// GET /api/documents/12345 (ä»–äººã®æ–‡æ›¸ã‚¢ã‚¯ã‚»ã‚¹)
// DELETE /api/users/victim/files/important.pdf (ä»–äººã®ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤)
// PUT /api/profiles/admin_profile_id {"role": "admin"} (æ¨©é™æ˜‡æ ¼)
"#,
        expected_vulnerabilities: vec![VulnType::IDOR],
        expected_confidence_min: 7,
        severity: BenchmarkSeverity::Medium,
        _description: "IDORæ”»æ’ƒ - èªå¯ãƒã‚§ãƒƒã‚¯ä¸å‚™",
        _real_world_context: "REST APIã§ã®å…¸å‹çš„ãªIDORè„†å¼±æ€§ã€‚æ”»æ’ƒè€…ãŒä»–ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒªã‚½ãƒ¼ã‚¹ã«ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½",
    },

    RealWorldBenchmark {
        name: "Weak file upload validation",
        cve_id: None,
        language: Language::Python,
        code: r#"
import os
from werkzeug.utils import secure_filename

def upload_user_avatar(file, user_id):
    # å¼±ã„æ¤œè¨¼ï¼šæ‹¡å¼µå­ã®ã¿ãƒã‚§ãƒƒã‚¯
    allowed_extensions = {'.jpg', '.jpeg', '.png', '.gif'}
    filename = file.filename
    
    if not any(filename.lower().endswith(ext) for ext in allowed_extensions):
        return {"error": "Invalid file type"}
    
    # å±é™ºï¼šãƒ•ã‚¡ã‚¤ãƒ«åæ¤œè¨¼ä¸ååˆ†
    upload_dir = f"/uploads/avatars/{user_id}/"
    os.makedirs(upload_dir, exist_ok=True)
    
    file_path = os.path.join(upload_dir, filename)
    file.save(file_path)
    
    return {"success": True, "path": file_path}

def process_document_upload(file, document_type):
    # ã•ã‚‰ã«å±é™ºï¼šContent-Typeã®ã¿ä¿¡é ¼
    allowed_types = ['application/pdf', 'text/plain', 'application/msword']
    
    if file.content_type not in allowed_types:
        return {"error": "Unsupported document type"}
    
    # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹æ¤œè¨¼ãªã—
    filename = secure_filename(file.filename)
    upload_path = f"/app/documents/{document_type}/{filename}"
    
    file.save(upload_path)
    return {"uploaded": upload_path}

# æ‚ªç”¨ä¾‹:
# avatar.php.jpg (äºŒé‡æ‹¡å¼µå­)
# document.pdf (å®Ÿéš›ã¯PHPã‚¹ã‚¯ãƒªãƒ—ãƒˆã€Content-Typeå½è£…)
"#,
        expected_vulnerabilities: vec![VulnType::AFO],
        expected_confidence_min: 6,
        severity: BenchmarkSeverity::Medium,
        _description: "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¤œè¨¼ä¸å‚™",
        _real_world_context: "Webã‚¢ãƒ—ãƒªã§ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã«ãŠã‘ã‚‹å…¸å‹çš„ãªæ¤œè¨¼ä¸å‚™ã€‚æ”»æ’ƒè€…ãŒæ‚ªæ„ã®ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å®Ÿè¡Œå¯èƒ½",
    },

    // === Complex Multi-vulnerability Cases ===
    RealWorldBenchmark {
        name: "E-commerce checkout - Multiple vulnerabilities",
        cve_id: None,
        language: Language::Python,
        code: r#"
import json
import subprocess
import sqlite3

def process_payment(user_id, payment_data, order_details):
    # 1. SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³
    user_query = f"SELECT * FROM users WHERE id = {user_id}"
    user = db.execute(user_query).fetchone()
    
    # 2. ã‚³ãƒãƒ³ãƒ‰ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³  
    payment_processor = payment_data.get('processor', 'stripe')
    cmd = f"payment_cli --processor {payment_processor} --amount {order_details['total']}"
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    
    # 3. ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³
    if 'promo_data' in payment_data:
        promo_info = json.loads(payment_data['promo_data'])
        # ã•ã‚‰ã«å±é™ºï¼špickleãƒ‡ãƒ¼ã‚¿ã‚‚å‡¦ç†
        if 'serialized_discount' in promo_info:
            import pickle
            discount = pickle.loads(promo_info['serialized_discount'])
    
    # 4. ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«
    receipt_template = order_details.get('receipt_template', 'default.html')
    with open(f"/app/templates/{receipt_template}", 'r') as f:
        template = f.read()
    
    # 5. SSRF
    webhook_url = payment_data.get('webhook_url')
    if webhook_url:
        import requests
        requests.post(webhook_url, json={"order_id": order_details['id']})
    
    return {"status": "processed", "transaction_id": result.stdout.strip()}

# ã“ã®ä¸€ã¤ã®é–¢æ•°ã«è¤‡æ•°ã®æ·±åˆ»ãªè„†å¼±æ€§ãŒå«ã¾ã‚Œã¦ã„ã‚‹
"#,
        expected_vulnerabilities: vec![VulnType::SQLI, VulnType::RCE, VulnType::LFI, VulnType::SSRF],
        expected_confidence_min: 8,
        severity: BenchmarkSeverity::Critical,
        _description: "è¤‡åˆè„†å¼±æ€§ - å®Ÿéš›ã®Eã‚³ãƒãƒ¼ã‚¹æ±ºæ¸ˆå‡¦ç†",
        _real_world_context: "å®Ÿéš›ã®Eã‚³ãƒãƒ¼ã‚¹ã‚µã‚¤ãƒˆã®æ±ºæ¸ˆå‡¦ç†ã«è¦‹ã‚‰ã‚Œã‚‹è¤‡æ•°è„†å¼±æ€§ã®çµ„ã¿åˆã‚ã›ã€‚å˜ä¸€é–¢æ•°ã«å¤šæ•°ã®æ”»æ’ƒãƒ™ã‚¯ã‚¿ãƒ¼ãŒå­˜åœ¨",
    },
    ]
}

#[derive(Debug)]
struct BenchmarkResult {
    detected_vulnerabilities: Vec<VulnType>,
    confidence_score: i32,
    analysis_quality: f64,
    poc_quality: f64,
    detection_accuracy: f64,
}

async fn test_benchmark_case(
    benchmark: &RealWorldBenchmark,
    model: &str,
) -> Result<BenchmarkResult> {
    // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    let temp_dir = tempdir()?;
    let file_extension = match benchmark.language {
        Language::JavaScript => "js",
        Language::Python => "py",
        Language::TypeScript => "ts",
        Language::Rust => "rs",
        Language::Java => "java",
        Language::Go => "go",
        Language::Ruby => "rb",
        Language::C => "c", 
        Language::Cpp => "cpp",
        _ => "txt",
    };
    
    let test_file = temp_dir.path().join(format!("test.{}", file_extension));
    std::fs::write(&test_file, benchmark.code)?;

    // ãƒ‘ãƒ¼ã‚µãƒ¼ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
    let mut parser = CodeParser::new()?;
    parser.add_file(&test_file)?;
    let context = parser.build_context_from_file(&test_file)?;

    // è§£æå®Ÿè¡Œ
    let response = analyze_file(
        &test_file,
        model,
        &[test_file.clone()],
        0,
        &context,
        0,
        false,
        &None,
        None,
        &LocaleLanguage::Japanese,
    ).await?;

    // çµæœåˆ†æ
    let detected_vulnerabilities = response.vulnerability_types;
    let confidence_score = response.confidence_score;

    // æ¤œå‡ºç²¾åº¦è¨ˆç®—
    let expected_set: std::collections::HashSet<_> = benchmark.expected_vulnerabilities.iter().collect();
    let detected_set: std::collections::HashSet<_> = detected_vulnerabilities.iter().collect();
    
    let true_positives = expected_set.intersection(&detected_set).count();
    let _false_positives = detected_set.difference(&expected_set).count();
    let _false_negatives = expected_set.difference(&detected_set).count();
    
    let precision = if detected_set.len() > 0 {
        true_positives as f64 / detected_set.len() as f64
    } else {
        if expected_set.is_empty() { 1.0 } else { 0.0 }
    };
    
    let recall = if expected_set.len() > 0 {
        true_positives as f64 / expected_set.len() as f64
    } else {
        1.0
    };
    
    let f1_score = if precision + recall > 0.0 {
        2.0 * (precision * recall) / (precision + recall)
    } else {
        0.0
    };

    // è§£æå“è³ªè©•ä¾¡ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    let analysis_quality = if response.analysis.len() > 100 && 
                             response.analysis.to_lowercase().contains("è„†å¼±") {
        85.0
    } else if response.analysis.len() > 50 {
        70.0
    } else {
        40.0
    };

    // PoCå“è³ªè©•ä¾¡ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    let poc_quality = if response.poc.len() > 50 &&
                        (response.poc.contains("curl") || 
                         response.poc.contains("SELECT") ||
                         response.poc.contains("<script>") ||
                         response.poc.contains("../") ||
                         response.poc.contains("http://")) {
        80.0
    } else if response.poc.len() > 20 {
        60.0
    } else {
        30.0
    };

    Ok(BenchmarkResult {
        detected_vulnerabilities,
        confidence_score,
        analysis_quality,
        poc_quality,
        detection_accuracy: f1_score * 100.0,
    })
}

#[tokio::test]
async fn test_critical_severity_benchmarks() -> Result<()> {
    // API key check
    if std::env::var("OPENAI_API_KEY").is_err() {
        println!("OPENAI_API_KEY not set, skipping critical severity benchmark test");
        return Ok(());
    }

    let model = "gpt-4.1-mini";

    let benchmarks = get_real_world_benchmarks();
    let critical_benchmarks: Vec<_> = benchmarks
        .iter()
        .filter(|b| matches!(b.severity, BenchmarkSeverity::Critical))
        .collect();

    println!("ğŸ”¥ ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«è„†å¼±æ€§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ: {}ã‚±ãƒ¼ã‚¹", critical_benchmarks.len());

    let mut detection_scores = Vec::new();
    let mut confidence_scores = Vec::new();
    let mut failed_cases = Vec::new();

    for benchmark in critical_benchmarks {
        println!("  ãƒ†ã‚¹ãƒˆä¸­: {} - {}", benchmark.name, 
                if let Some(cve) = benchmark.cve_id { cve } else { "No CVE" });
        
        let result = test_benchmark_case(benchmark, model).await?;
        
        detection_scores.push(result.detection_accuracy);
        confidence_scores.push(result.confidence_score as f64);

        if result.detection_accuracy >= 90.0 && result.confidence_score >= benchmark.expected_confidence_min {
            println!("    âœ… æ¤œå‡ºæˆåŠŸ: {:.1}% (ä¿¡é ¼åº¦={})", 
                    result.detection_accuracy, result.confidence_score);
            println!("       æ¤œå‡ºã•ã‚ŒãŸè„†å¼±æ€§: {:?}", result.detected_vulnerabilities);
        } else {
            println!("    âŒ æ¤œå‡ºå¤±æ•—: {:.1}% (ä¿¡é ¼åº¦={})", 
                    result.detection_accuracy, result.confidence_score);
            println!("       æœŸå¾…: {:?}", benchmark.expected_vulnerabilities);
            println!("       å®Ÿéš›: {:?}", result.detected_vulnerabilities);
            failed_cases.push(benchmark.name);
        }
    }

    let avg_detection = detection_scores.iter().sum::<f64>() / detection_scores.len() as f64;
    let avg_confidence = confidence_scores.iter().sum::<f64>() / confidence_scores.len() as f64;

    println!("\nğŸ“Š ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«è„†å¼±æ€§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ:");
    println!("  å¹³å‡æ¤œå‡ºç²¾åº¦: {:.1}%", avg_detection);
    println!("  å¹³å‡ä¿¡é ¼åº¦: {:.1}", avg_confidence);

    if !failed_cases.is_empty() {
        println!("\nâŒ å¤±æ•—ã—ãŸã‚±ãƒ¼ã‚¹:");
        for case in &failed_cases {
            println!("    - {}", case);
        }
    }

    // ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«è„†å¼±æ€§ã¯95%ä»¥ä¸Šã®æ¤œå‡ºç²¾åº¦ã‚’è¦æ±‚
    assert!(
        avg_detection >= 95.0,
        "ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«è„†å¼±æ€§æ¤œå‡ºç²¾åº¦ãŒåŸºæº–ã‚’ä¸‹å›ã£ã¦ã„ã¾ã™: {:.1}% (è¦æ±‚: 95.0%)",
        avg_detection
    );

    println!("\nğŸ‰ ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«è„†å¼±æ€§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆåˆæ ¼!");
    Ok(())
}

#[tokio::test]
async fn test_comprehensive_benchmark_suite() -> Result<()> {
    // API key check
    if std::env::var("OPENAI_API_KEY").is_err() {
        println!("OPENAI_API_KEY not set, skipping comprehensive benchmark test");
        return Ok(());
    }

    let model = "gpt-4.1-mini";

    let benchmarks = get_real_world_benchmarks();
    println!("ğŸ§ª åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚¤ãƒ¼ãƒˆ: {}ã‚±ãƒ¼ã‚¹", benchmarks.len());

    let mut severity_stats = HashMap::new();
    let mut total_detection_score = 0.0;
    let mut total_analysis_quality = 0.0;
    let mut total_poc_quality = 0.0;
    let mut total_tests = 0;

    for benchmark in &benchmarks {
        println!(
            "  [{}/{}] ãƒ†ã‚¹ãƒˆä¸­: {}",
            total_tests + 1,
            benchmarks.len(),
            benchmark.name
        );

        let result = test_benchmark_case(benchmark, model).await?;

        // çµ±è¨ˆæ›´æ–°
        let severity_key = format!("{:?}", benchmark.severity);
        let entry = severity_stats.entry(severity_key).or_insert((0.0, 0.0, 0.0, 0));
        entry.0 += result.detection_accuracy;
        entry.1 += result.analysis_quality;
        entry.2 += result.poc_quality;
        entry.3 += 1;

        total_detection_score += result.detection_accuracy;
        total_analysis_quality += result.analysis_quality;
        total_poc_quality += result.poc_quality;
        total_tests += 1;
    }

    let avg_detection = total_detection_score / total_tests as f64;
    let avg_analysis = total_analysis_quality / total_tests as f64;
    let avg_poc = total_poc_quality / total_tests as f64;

    println!("\nğŸ“Š åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ:");
    println!("  å…¨ä½“æ¤œå‡ºç²¾åº¦: {:.1}%", avg_detection);
    println!("  å…¨ä½“è§£æå“è³ª: {:.1}%", avg_analysis);
    println!("  å…¨ä½“PoCå“è³ª: {:.1}%", avg_poc);

    println!("\næ·±åˆ»åº¦åˆ¥çµæœ:");
    for (severity, (detection_sum, analysis_sum, poc_sum, count)) in severity_stats {
        println!("  {}: æ¤œå‡º={:.1}%, è§£æ={:.1}%, PoC={:.1}% ({}ã‚±ãƒ¼ã‚¹)",
                severity,
                detection_sum / count as f64,
                analysis_sum / count as f64,
                poc_sum / count as f64,
                count);
    }

    // ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆé‡ã¿ä»˜ãå¹³å‡ï¼‰
    let comprehensive_score = (avg_detection * 0.5) + (avg_analysis * 0.3) + (avg_poc * 0.2);

    println!("\nç·åˆè©•ä¾¡ã‚¹ã‚³ã‚¢: {:.1}%", comprehensive_score);

    // åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯85%ä»¥ä¸Šã®ã‚¹ã‚³ã‚¢ã‚’è¦æ±‚
    assert!(
        comprehensive_score >= 85.0,
        "åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚³ã‚¢ãŒåŸºæº–ã‚’ä¸‹å›ã£ã¦ã„ã¾ã™: {:.1}% (è¦æ±‚: 85.0%)",
        comprehensive_score
    );

    println!("\nğŸ‰ åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚¤ãƒ¼ãƒˆåˆæ ¼!");
    Ok(())
}

#[tokio::test]
async fn test_multi_vulnerability_detection() -> Result<()> {
    // API key check
    if std::env::var("OPENAI_API_KEY").is_err() {
        println!("OPENAI_API_KEY not set, skipping multi-vulnerability test");
        return Ok(());
    }

    let model = "gpt-4.1-mini";

    let benchmarks = get_real_world_benchmarks();
    // è¤‡æ•°è„†å¼±æ€§ã‚’å«ã‚€ã‚±ãƒ¼ã‚¹ã®ã¿ãƒ†ã‚¹ãƒˆ
    let multi_vuln_cases: Vec<_> = benchmarks
        .iter()
        .filter(|b| b.expected_vulnerabilities.len() > 1)
        .collect();

    println!("ğŸ” è¤‡æ•°è„†å¼±æ€§æ¤œå‡ºãƒ†ã‚¹ãƒˆ: {}ã‚±ãƒ¼ã‚¹", multi_vuln_cases.len());

    let mut total_recall = 0.0;
    let mut total_precision = 0.0;
    let mut total_tests = 0;

    for benchmark in multi_vuln_cases {
        println!("  ãƒ†ã‚¹ãƒˆä¸­: {} (æœŸå¾…è„†å¼±æ€§æ•°: {})", 
                benchmark.name, benchmark.expected_vulnerabilities.len());
        
        let result = test_benchmark_case(benchmark, model).await?;

        let expected_set: std::collections::HashSet<_> = benchmark.expected_vulnerabilities.iter().collect();
        let detected_set: std::collections::HashSet<_> = result.detected_vulnerabilities.iter().collect();
        
        let true_positives = expected_set.intersection(&detected_set).count();
        let false_positives = detected_set.difference(&expected_set).count();
        let false_negatives = expected_set.difference(&detected_set).count();
        
        let precision = if detected_set.len() > 0 {
            true_positives as f64 / detected_set.len() as f64
        } else {
            0.0
        };
        
        let recall = if expected_set.len() > 0 {
            true_positives as f64 / expected_set.len() as f64
        } else {
            1.0
        };

        total_recall += recall;
        total_precision += precision;
        total_tests += 1;

        println!("    å†ç¾ç‡: {:.1}%, é©åˆç‡: {:.1}% (TP={}, FP={}, FN={})",
                recall * 100.0, precision * 100.0, true_positives, false_positives, false_negatives);
    }

    let avg_recall = (total_recall / total_tests as f64) * 100.0;
    let avg_precision = (total_precision / total_tests as f64) * 100.0;
    let f1_score = if avg_recall + avg_precision > 0.0 {
        2.0 * (avg_recall * avg_precision) / (avg_recall + avg_precision)
    } else {
        0.0
    };

    println!("\nğŸ“Š è¤‡æ•°è„†å¼±æ€§æ¤œå‡ºçµæœ:");
    println!("  å¹³å‡å†ç¾ç‡ (Recall): {:.1}%", avg_recall);
    println!("  å¹³å‡é©åˆç‡ (Precision): {:.1}%", avg_precision);
    println!("  F1ã‚¹ã‚³ã‚¢: {:.1}%", f1_score);

    // è¤‡æ•°è„†å¼±æ€§æ¤œå‡ºã¯F1ã‚¹ã‚³ã‚¢80%ä»¥ä¸Šã‚’è¦æ±‚
    assert!(
        f1_score >= 80.0,
        "è¤‡æ•°è„†å¼±æ€§æ¤œå‡ºF1ã‚¹ã‚³ã‚¢ãŒåŸºæº–ã‚’ä¸‹å›ã£ã¦ã„ã¾ã™: {:.1}% (è¦æ±‚: 80.0%)",
        f1_score
    );

    println!("âœ… è¤‡æ•°è„†å¼±æ€§æ¤œå‡ºãƒ†ã‚¹ãƒˆåˆæ ¼!");
    Ok(())
}